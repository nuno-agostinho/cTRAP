% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compare.R
\name{processByChunks}
\alias{processByChunks}
\title{Process data columns by chunks}
\usage{
processByChunks(
  data,
  FUN,
  num,
  ...,
  threads = 1,
  chunkGiB = 1,
  verbose = FALSE
)
}
\arguments{
\item{data}{Data matrix or character containing a file path}

\item{FUN}{Function: function to run for each chunk}

\item{num}{Numeric: numbers of methods to run per chunk}

\item{...}{Arguments passed to \code{FUN}}

\item{threads}{Integer: number of parallel threads}

\item{chunkGiB}{Integer: size in gibibyte of file to load on-demand (higher
values increase RAM usage)}

\item{verbose}{Boolean: print additional details?}
}
\value{
Results of running \code{FUN}
}
\description{
By loading and processing chunks of data, the usage of RAM is minimized. For
instance, loading a chunk of 10000 columns and 14000 rows takes ~1 GiB RAM
(10000 * 14000 * 8 bytes / 1024^3 = 1.04 GiB).
}
\details{
If argument \code{data} is a data matrix, it will be processed as a single
chunk. Otherwise, if it is a file path, data columns will be loaded and
processed from file in chunks with size of \code{chunkGiB}. All rows are
processed simultaneously (i.e. chunks only apply to columns).
}
\keyword{internal}
