% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/compare.R
\name{processByChunks}
\alias{processByChunks}
\title{Process data column by chunks}
\usage{
processByChunks(data, FUN, num, ..., threads = 1, chunkSize = 10000)
}
\arguments{
\item{data}{Data matrix or \code{perturbationChanges} object}

\item{FUN}{Function: function to run for each chunk}

\item{num}{Numeric: numbers of methods to run per chunk}

\item{...}{Arguments passed to \code{FUN}}

\item{threads}{Integer: number of parallel threads}

\item{chunkSize}{Integer: number of columns to load on-demand (a higher value
increases RAM usage, but decreases running time)}
}
\value{
Results of running \code{FUN}
}
\description{
Columns will be processed per chunk if argument \code{data} is a
\code{perturbationChanges} object containing a file path instead of a data
matrix. Otherwise, the data will be processed as a single chunk.
}
\details{
For instance, loading a chunk of 10000 CMap pertubations requires ~1GB of RAM
compared to loading the whole dataset.
}
\keyword{internal}
